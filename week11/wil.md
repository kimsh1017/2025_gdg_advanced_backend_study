# **Chapter 6. B-Tree Variants**
---

B-Tree 변형은 몇가지 공통점을 가지고 있다.

- 트리 구조
- 분할과 병합을 통한 밸런싱
- 조회 및 삭제 알고리즘

또 아래와 같은 세부사항들은 구현에 따라 달라지기도 한다.

- 동시성
- 디스크 페이지 표현 방식
- 형제 노드 링크
- 유지보수 프로세스

이번 쳅터에서 우린 효율적인 B-Tree 구조를 구현하는 여러 테크닉들과 사용하는 구조에 대해 이야기할 예정이다.

- Copy-on-wirte B-Tree 는 B-Tree 와 유사한 구조를 가지지만, 노드들이 immutable 하고 in-place 업데이트를 할 수 없다. 대신 페이지들이 복사되어 업데이트 되고, 새로운 위치에 쓰여진다.
- Lazy B-Tree는 같은 노드에 대한 수정을 버퍼링하여 디스크 I/O 요청의 숫자를 줄인다. (다음 챕터에서 우리는 추가적으로 two-component LSM tree 도 다루는데, 이는 버퍼링을 한 단계 더 발전시켜 완전히 불변하는 B-트리를 구현한다)
- FD-Tree는 버퍼링에 대해 다른 접근법을 가져가는데, LSM 트리와 다소 유사하다. FD-Tree는 작은 B-Tree에서 수정사항을 버퍼링한다. 이 트리가 가득 차면, 그 내용은 즉시 불변 런(immuatable run)으로 기록된다. 업데이트는 불변 런의 레벨들 사이에서 상위 레벨에서 하위 레벨로 연쇄적인 방식으로 전파된다.
- BW-Tree는 B-Tree 노드를 더 작은 파트로 분리하여 append-only 방식으로 내용을 쓴다. 이것은 작은 크기의 다른 노드들을 함께 업데이트하면서 쓰기 비용을 줄여준다.
- Cache-oblivious B-Tree는 디스크 자료 구조를 마치 메모리에서 구현하는 방식과 유사하게 처리할 수 있도록 한다.

## **Copy-on-Write**

---

몇몇 DB들은 복잡한 래치 메커니즘을 구현하는것 대신에, copy-on-write 테크닉을 사용하여 동시 연산 환경에서 데이터 무결성을 보장한다. 이 케이스에선 페이지가 수정될때마다 내용이 복사되고, 복사된 페이지가 원본 대신에 수정된 다음 병렬 트리 구조가 생성된다.

쓰기와 동시에 진행중인 reader는 오래된 트리 버전에 접근 가능 하도록 트리가 계속 남아있지만, 수정된 페이지에 접근하는 writer는 이전의 쓰기 연산이 종료될때까지 기다려야한다. 새로운 페이지 구조가 생성된 후에, 최상단 페이지 포인터가 원자적으로 업데이트된다. 아래 그림에서 새 트리가 이전 트리와 병렬로 생성되고 변경되지 않은 페이지들은 재사용하는 것을 볼 수 있다.

이 접근 방식의 명백한 단점은 이 방식이 더 많은 공간과 처리 시간을 요구한다는 것이다. (비록 오래된 버전들이 짧은 시간 동안만 유지되긴 하지만, 기존 페이지들을 사용하는 동시 작업들이 완료된 후 즉시 페이지들을 회수할 수 있음에도 불구하고) 전체 페이지 내용을 복사해야 하기 때문이다. 그러나 B-Tree는 일반적으로 얕기 때문에, 이 접근법의 단순성과 장점들이 여전히 단점들을 상회하는 경우가 많다.

이 접근 방식의 가장 큰 장점은 readers는 동기화가 필요없다는 것이다. 왜냐하면 이미 쓰여진 페이지들은 immuatable 하고 추가적인 latching 없이 접근이 가능하기 때문이다. 쓰기가 복사된 페이지를 상대로 수행되므로 reader는 쓰기에 block되지 않는다. 어떤 연산도 완료되지 않은 상태를 관측할 수 없고, 시스템 충돌도 페이지를 손상된 상태로 남길 수 없다. (최상단 포인터는 오직 모든 페이지 수정이 완료된 이후에 변경되기 때문)

### **Implementing Copy-on-Write: LMDB**

copy-on-write 방식을 사용하는 스토리지 엔진 중 하나는 LMDB(Lightning Memory-Mapped Database)이다. 이는 OpenLDAP project에서 사용되는 키-밸류 저장소이다. 디자인과 아키텍쳐때문에 LMDB는 페이지 캐시, WAL 체크포인팅 혹은 압축을 요구하지 않는다.

LMDB는 단일 레벨 데이터 저장소로 구현된다. 이것은 읽기와 쓰기 연산이 추가적인 어플리케이션 레벨 캐싱 없이 메모리 맵을 통해 곧바로 수행된다는 의미이다. 이것은 또한 페이지들이 추가적인 구체화를 요구하지 않으며, 읽기가 중간 버퍼에 데이터를 복사하지 않고 메모리 맵에 곧바로 수행된다는 것을 의미한다. 수정이 진행되는 동안 루트에서 타깃 리프노드까지의 경로에 있는 모든 노드들은 복사되고, 잠재적으로 수정될 수 있다. 업데이트가 전파되는 노드만 변경되고, 나머지 노드는 그대로 유지된다.

LMDB는 오직 두개의 루트 노드 버전만 유지한다. 최근 버전, 그리고 곧 커밋될 새로운 버전. 모든 쓰기는 루트 노드를 거쳐야 하기 때문에 이걸로도 충분하다. 새 루트가 생성된 이후, 오래된 버전은 새 읽기와 쓰기에서 사용불가능해진다. 읽기가 오래된 트리 부분을 가리키는게 종료되자마자 해당 페이지 메모리는 회수되고 재사용된다. LMDB는 append-only 디자인이기 때문에, 형재 포인터를 사용하지 않고, 순차 탐색을 진행하는 동안 부모 노드로 되돌아가야만 한다.

이 디자인에선 복사한 노드에서 오래된 데이터를 남겨두는 것이 비실용적이다. MVCC를 위해 사용할 수 있고 현재 진행 중인 읽기 트랜잭션을 만족시킬 수 있는 복사본이 이미 있기 때문이다. 데이터베이스 구조는 본질적으로 다중 버전이며, 읽기 작업은 쓰기 작업과 어떤 식으로도 간섭하지 않기 때문에 어떤 락도 없이 실행될 수 있다.

>> MVCC와 동일하게 사용된다. 그러나 MVCC처럼 여러 버전을 오래 남겨둘 필요가 없다.

## **Abstracting Node Updates**

---

디스크 페이지를 업데이트하려면, 어쨌든 우리는 먼저 메모리 표현부터 업데이트해야한다. 그러나 메모리에서 노드를 표현하는 여러 방법이 있다. (우리는 캐시된 노드 버전에 직접 접근할 수도 있고, wapper 객체를 통해 접근할 수도 있고, 사용하는 언어에 네이티브한 메모리 내 표현을 생성할 수도 있다.) 

비 관리형 메모리 언어에선 B-Tree 노드에 저장된 원시 이진 데이터(raw binary data)를 재해석하고 네이티브 포인터를 사용하여 직접 조작할 수 있다. 이 경우, 노드는 구조체로 정의되며, 포인터 뒤에 있는 원시 이진 데이터와 런타임 캐스팅을 사용한다. 대부분의 경우 이들은 페이지 캐시에 의해 관리되는 메모리 영역을 가리키거나 메모리 매핑을 사용한다.
>> C, C++처럼 메모리를 직접 관리하는 언어에선 디스크 페이지의 데이터들을 바이너리 포맷된 상태 그대로 가져와서 구조체로 형성해 사용함. 이 구조체 형식과 포인터는 런타임에 동적으로 캐스팅될 수 있음(리프 노드, 루트 노드 등)

대안적으로, B-Tree 노드들은 해당 언어에 고유한 객체나 구조체로 구체화될 수 있다. 이러한 구조체들은 삽입, 업데이트, 삭제에 사용될 수 있다. 플러시 과정에서 변경사항들이 메모리의 페이지에 먼저 적용되고, 이후 디스크에 반영된다. 이 접근법은 기본 원시 페이지에 대한 변경이 중간 객체들에 대한 접근과 별도로 관리되기 때문에 동시 접근을 단순화하는 장점이 있지만, 동일한 페이지의 두 가지 버전(원시 이진 데이터와 언어 고유 버전)을 메모리에 저장해야 하므로 더 높은 메모리 오버헤드를 초래한다. 

>> 페이지를 데이터를 해석해서 Class 처럼 고유 객체나 구조체로 변경해 저장하는 방식. 페이지 데이터를 객체로 복사해서 사용하는 방식 → LMDB 처럼 복사 후 변경에 용이함

세 번째 접근법은 B-Tree에서 변경사항이 수행되는 즉시 이를 구체화하는 래퍼 객체를 통해 노드를 뒷받침하는 버퍼에 대한 접근을 제공하는 것이다. 이 접근법은 관리형 메모리 모델을 사용하는 언어에서 가장 자주 사용한다. 래퍼 객체들은 뒷받침 버퍼에 변경사항을 적용한다.

>> 이진 데이터를 감싸는 크래스를 사용하는 방식, 클래스 내부에서 flag등을 사용함

온디스크 페이지들, 그들의 캐시된 버전들, 그리고 인메모리 표현들을 별도로 관리하는 것은 이들이 서로 다른 생명주기를 가질 수 있도록 한다. 예를 들어, 삽입, 업데이트, 삭제 작업들을 버퍼링하고, 읽기 과정에서 메모리에서 만들어진 변경사항들을 원본 온디스크 버전과 조정할 수 있다.

>> 그러니까 첫번째 방식은 디스크 페이지 데이터를 필요하면 직접 binary 데이터로 가져와 구조체로 생성하고, 포인터를 통해 가리키며 수정하는 방식.
두번째 방식은 디스크 페이지 데이터를 직접 생성한 자료구조, Class 등으로 변환하여 수정하는 방식,
세번째 방식은 바이트 데이터를 감싸는 래퍼 클래스를 사용하는 방식

## Lazy B-Trees

---

일부 알고리즘들(이 책에서는 lazy B-Trees 라고 부름)은 B-트리 업데이트 비용을 줄이고, 더 가볍고 동시성 및 업데이트 친화적인 인메모리 구조를 사용하여 업데이트와 전파를 버퍼링하고 지연시킨다.

### WiredTiger

lazy B-Tree를 구현하기 위해 어떻게 버퍼링을 사용하는지 알아보자. 그걸 위해 우리는 B-Tree 노드들이 paged 되자마자 메모리에 구체화 할 수 있고, 이 구조를 변경을 플러시할 준비가 될 때 까지 기록하는데 사용할 수 있다.

비슷한 접근법이 MongoDB의 기본 스토리지 엔진인 WiredTiger에서 사용된다. WiredTiger의 로우 스토어(row store) B-트리 구현은 메모리 페이지와 디스크 페이지에 대해 다른 형식을 사용한다. 메모리 페이지는 영속화되기 전에 조정 단계를 거쳐야만 한다.

그림에서 우린 WiredTiger의 페이지와 구성을 B-Tree로 개략적으로 표현한 것을 볼 수 있다. 클린 페이지(clean page)는 디스크 상의 페이지 이미지에서 처음부터 존재했던 인덱스만을 포함한다. (clean page = dirty page의 반대, 아직 변경이 하나도 없어서, 디스크 페이지와 동일한 페이지를 이야기한다.) 변경은 먼저 update 버퍼에 저장된다.

업데이트 버퍼는 읽기 과정에서 접근할 수 있다. 해당하는 내용들은 원본 디스크 페이지 내용에 병합되어 최신 데이터를 반환한다. 페이지가 플러시될 때 업데이트 버퍼 내용들은 페이지 내용들과 조정을 거치고 디스크에 영속화되고, 원본 페이지를 덮어쓴다. 조정된 페이지의 크기가 최대 값을 넘어가면, 여러 페이지로 분할된다. 업데이트 버퍼는 search tree와 복잡도가 유사하지만, 동시성에 더 이점이 있는 skiplist를 통해 구현된다.

그림은 WiredTiger에서 디스크의 기본 이미지를 참조하는 메모리 버전의 clean, dirty page를 각각 보여준다. 더디 페이지는 update 버퍼를 추가적으로 가지고 있다. 

이 방식의 주요 장점은 페이지 업데이트와 구조적 변경(병합, 분할)이 백그라운드 스레드에서 수행되고, 읽기 쓰기 프로세스들이 끝날때까지 기다릴 필요가 없다는 것이다.

### Lazy-Adaptive Tree

개별적인 노드에 대한 업데이트를 버퍼링하는 대신에, 우리는 노드들을 서브 트리로 그룹화하고 각각트이 서브 트리에 대해서 업데이트 버퍼를 붙여서 배치 연산을 할 수도 있다. 이 경우 업데이트 버퍼들은 해당 서브트리의 탑 노드와 거기서 내려가는 모든 노드에서 수행되는 연산들을 추적한다. 이 일고리즘을 Lazy-Adaptive Tree (LA-Tree)라고 이야기한다. 

데이터 레코드를 삽입할때, 새로운 엔트리가 먼저 루트 노드의 업데이트 버퍼에 추가된다. 이 버퍼가 가득 차게 되면, 해당 내용들을 복사하고 변경사항들을 더 낮은 레벨의 트리에 있는 버퍼로 전파하면서 비운다. 이 연산은 아래 레벨이 채워지고 결국 리프 노드에 다다를 때까지 재귀적으로 계속될 수 있다 

그림에서 우린 LA Tree 와 그룹화된 서브트리 노드들에 대응하는 계단식 버퍼 구조에 대해 볼 수 있다. 회색 박스는 루트 버퍼에서 전파된 변경사항들을 나타낸다.

버퍼는 계층적 의존성을 가지고 계단화(cascaded)된다. 모든 변경은 높은 레벨 버퍼에서 낮은 레벨 버퍼로 전파된다. 변경이 리프 레벨에 도달하면, 트리 내용들과 구조에 대한 모든 변경사항들이 한번에 적용된다. 분리된 페이지에 대한 변경을 연속으로 수행하는 대신에, 페이지들은 한번의 수행으로 업데이트되고, 높은 레벨에서 분할과 병합의 전파가 한꺼번에 적용되므로 더 적은 디스크 접근과 구조 변화가 요구된다. 

여기서 설명하는 버퍼링 접근 방식은 쓰기 작업을 배치하여 트리 업데이트 시간을 최적화하지만, 약간 다른 방식으로 수행된다. 두 알고리즘 모두 인메모리 버퍼링 구조와 오래된 디스크 데이터와의 병합/조정에 대한 추가적인 조회가 필요하다.

## FD-Trees

---

버퍼링은 DB 스토리지에서 널리 사용되는 개념 중 하나이다. 버퍼링은 작은 랜덤 쓰기 연산을 피하고, 하나의 큰 쓰기 연산을 수행하도록 도와준다. HDD에서 랜덤 쓰기는 헤더 이동 때문에 느리다. SSD에서는 움직이는 파트는 없지만 쓰기 I/O는 추가적인 가비지 컬랙션 패널티가 존재한다.

>> HDD의 I/O 오버헤드(헤드 이동 지연) 때문에, 랜덤 쓰기와 I/O 횟수를 줄이기 위해 B-Tree와 페이징을 사용했음

>> SSD는 랜덤 쓰기가 성능에 영향을 미치진 않지만 수정 작업에서 일어나는 erase가 오버헤드가 큼 → 이걸 줄이기 위한 자료구조가 FD-Tree

B-Tree를 유지하는 것은 많은 랜덤 쓰기를 요구한다. (리프 레벨 쓰기, 부모 노드로 전파되는 분할, 병합 등) 그러나 랜덤 쓰기를 피하면서도 노드 변경을 할 방법은 없을까?

지금까지 보조 버퍼를 생성하여 개별 노드나 노드 그룹에 대한 업데이트를 버퍼링하는 것에 대해 논의했다. 대안적 접근법은 append-only 스토리지와 병합 프로세스를 사용하여 서로 다른 노드들을 대상으로 하는 업데이트를 함께 그룹화하는 것인데, 이 아이디어는 LSM 트리에도 영감을 주었다. 이는 우리가 수행하는 모든 쓰기가 해당 쓰기를 위한 대상 노드를 찾을 필요가 없다는 것을 의미한다. 모든 업데이트는 단순히 추가되기만 한다. 인덱싱에 이 접근법을 사용하는 예시 중 하나가 플래시 디스크 트리(Flash Disk Tree, FD-Tree)이다.

>> Flash Disk Tree = SSD를 위한 트리 구조, 업데이트 연산을 전부 새로운 쓰기 연산으로 바꿔버림 + 버퍼링 적용해 랜덤 쓰기도 피함

FD-트리는 작은 가변 헤드 트리와 여러 개의 불변 정렬된 런(run)들로 구성됩니다. 이 접근법은 랜덤 쓰기 I/O가 필요한 표면 영역을 헤드 트리로 제한한다. (업데이트를 버퍼링하는 작은 B-트리) 헤드 트리가 가득 차면, 그 내용은 불변 런으로 전송된다. 새로 작성된 런의 크기가 임계값을 초과하면, 그 내용은 다음 레벨과 병합되어 상위 레벨에서 하위 레벨로 데이터 레코드를 점진적으로 전파한다.

>> LSM Tree처럼 구현되는 FD Tree 구현 내용. 가장 높은 위치(헤드 트리)만 가변적임, 헤드 트리가 가득차면 불변 런으로 변경되어 저장됨. → 레벨 당 불변 런 개수는 고정, 불변 런 개수가 제한 이상이면 → 레벨을 늘리면서 변경사항 전파. 전파하면서 데이터를 병합 정렬해 다시 쓴다.

>> 데이터가 레벨을 이동할때만 새로 쓰여짐, 런들은 불변임 → 랜덤 쓰기나 수정 오버헤드가 없다.

> 예시를 들어보자 (헤드 크기 2)
> 
- Head : [], Lv0 : []
- 데이터 삽입 : (A = 1, B =2)
- Head : [A = 1, B = 2], Lv1 = []
- 데이터 삽입 : C = 3 → 헤드 가득참, 아래 레벨로 전파
- Head : [C = 3] , Lv0 : [A = 1, B = 2]
- 데이터 삽입 : (D = 4, E = 5) → 헤드 가득차서 전파, Lv0도 가득차서 Lv1로 전파
- Head : [E = 5], Lv1 : [A = 1, B = 2, C = 3, D = 4]
    - 데이터 수정이 있는 경우도 Head에서 먼저 일어남
    - 데이터 조회시 헤드에서 이진 탐색으로 조회, 없으면 아래 레벨로 내려가서 조회함

### Fractional Cascading

FD-트리는 레벨 간의 포인터를 유지하기 위해 ractional cascading 이라는 기술을 사용한다. 이 방식은 정렬된 배열들의 cascade(연속적인 흐름)에서 항목을 찾는 비용을 줄이는 것을 도와준다. 첫 번째 배열에서 검색하려는 항목을 찾는 데는 log n 단계가 필요하지만, 이후의 검색은 이전 레벨에서 가장 가까운 일치 항목부터 시작하므로 훨씬 저렴하다.

레벨 간의 지름길은 이웃 레벨 배열 사이에 연결을 만들어 간격을 최소화함으로써 생성한다. 이는 상위 레벨에서 포인터가 없는 요소 그룹을 의미한다. 다리는 하위 레벨에서 상위 레벨로 요소를 가져와서, 만약 이미 존재하지 않는다면, 가져온 요소의 위치를 하위 레벨 배열에서 가리키도록 함으로써 만들어진다.

상위 레벨 배열의 모든 요소에서 다음 레벨의 가장 가까운 요소로 매핑을 생성할 수도 있지만, 이는 포인터 및 유지 관리에 너무 많은 오버헤드를 유발한다. 만약 상위 레벨에 이미 존재하는 항목만 매핑한다면, 요소 간의 간격이 너무 커지는 상황이 생길 수 있다. 이 문제를 해결하기 위해 하위 레벨 배열에서 매 N번째 항목을 상위 레벨로 가져온다.

예를 들어, 여러 개의 정렬된 배열이 있다고 가정해보자

- A1= [12, 24, 32, 34, 39]
- A2= [22, 25, 28, 30, 35]
- A3= [11, 16, 24, 26, 30]

우리는 더 높은 인덱스를 가진 배열에서 격리된 모든 요소를 가져와서 검색을 단순화하기 위해 요소 간의 간격을 연결할 수 있다. (2, 4번째 요소를 상위로 복사, 포인터(브릿지) 연결)

- A1= [12, 24, 25, 30, 32, 34, 39]
- A2= [16, 22, 25, 26, 28, 30, 35]
- A3= [11, 16, 24, 26, 30]

이 모든 배열에서 요소를 검색하려면 가장 높은 레벨에서 이진 검색을 수행한다. 검색 공간은 다리를 따라 검색된 항목의 대략적인 위치로 전달되므로 다음 레벨에서 크게 줄어든다. 이를 통해 여러 정렬된 실행을 연결하고 검색 비용을 줄일 수 있다.

### **Logarithmic Runs**

FD-트리는 분할 캐스케이딩을 로그 크기의 정렬된 런을 생성하는 것과 결합한다. 이 정렬된 런들은 k 인자만큼 크기가 증가하며, 이전 레벨과 현재 레벨을 병합하여 생성된다.

가장 높은 레벨의 런은 헤드 트리(head tree)가 가득 찼을 때 생성된다. 헤드 트리의 리프(leaf) 내용이 첫 번째 레벨에 기록된다. 헤드 트리가 다시 가득 차면, 그 내용은 첫 번째 레벨의 런들과 병합된다. 병합된 결과는 첫 번째 실행의 이전 버전을 대체한다.

더 낮은 레벨의 실행들은 더 높은 레벨의 실행들의 크기가 임계값에 도달했을 때 생성된다. 만약 더 낮은 레벨의 런이 이미 존재한다면, 그 내용은 더 높은 레벨의 내용과 병합된 결과로 대체된다. 이 과정은 LSM 트리에서의 압축(compaction)과 상당히 유사하다. LSM 트리에서는 변경 불가능한 테이블 내용이 병합되어 더 큰 테이블을 생성한다.

그림은 FD-트리의 개략적인 표현을 보여준다. 상단에는 헤드 B-트리가 있고, 두 개의 로그 런 L1과 L2, 그리고 그들 사이의 다리(bridges)가 있다.

모든 정렬된 런에 있는 항목들을 주소 지정 가능하도록 유지하기 위해, FD-트리는 분할 캐스케이딩의 개조된 버전을 사용한다. 여기서는 낮은 레벨 페이지의 헤드 요소들이 더 높은 레벨로 포인터로 전파된다. 이 포인터들을 사용하면 검색이 이미 더 높은 레벨에서 부분적으로 수행되었고 가장 가까운 일치 항목부터 계속될 수 있으므로, 낮은 레벨 트리에서의 검색 비용이 줄어든다.

>> 레벨간 런의 최상단 (런의 제일 앞의 요소)를 윗 레벨 런 요소에 추가, 포인터 연결

FD-트리는 페이지를 제자리에서 업데이트하지 않으며, 동일한 키에 대한 데이터 레코드가 여러 레벨에 존재할 수 있으므로, FD-트리의 삭제는 해당 키와 관련된 데이터 레코드가 삭제 대상으로 표시되었음을 나타내는 툼스톤(tombstones) (FD-트리 논문에서는 필터 항목(filter entries)이라고 부름)을 삽입하는 방식으로 작동한다. 이 툼스톤은 낮은 레벨의 해당 키에 대한 모든 데이터 레코드를 폐기해야 함을 의미한다. 툼스톤이 가장 낮은 레벨까지 전파되면, 더 이상 가려야 할 항목이 없으므로 폐기될 수 있다.

>> 삭제시에는 삭제 마크를 헤드 비트리에 저장하는 방식으로 작동 (조회 필터링)

>> 병합이 계속 진행되면서 아레 레벨로 마크가 계속 내려감 → 가장 낮은 레벨로 내려가면 없애도 됨